# -*- coding: utf-8 -*-
"""spam message detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sSMXdaDCHr7F69lrGGv2LQgqtgHvdYm2
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv("/content/spam.csv",encoding='latin-1')

df.head()

"""DATA CLEANING"""

df = df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'])

df.head()

df = df.rename({'v1':'diagnosis','v2':'message'},axis=1)

df.columns

df.head()

"""FEATURE ENGINEERING"""

import re

separators = [',' , ' ' , ';' , '+' , '-' , '!' , '?' , '&' , '$' , '_' , '@' , '/' , ':']
def count_words(message):
  for char in separators:
    message = message.replace(char,' ')
  words = message.split()
  return len(words)

df['message_length'] = df['message'].apply(lambda x: count_words(x))

symbols = r'[^a-zA-Z0-9]'
def symbols_count(message):
  count = len(re.findall(symbols,message))
  return count

df['symbol_density'] = df['message'].apply(lambda x:symbols_count(x))/df['message_length']

currency= r'[$€¥₹£]+'
def currency_count(message):
  list_currencies = re.findall(currency,message)
  return len(list_currencies)

df['currency_count'] = df['message'].apply(lambda x : currency_count(x))

digits = r'[0-9]'
def digit_count(message):
  list_digits = re.findall(digits,message)
  return len(list_digits)

df['digit_density'] = df['message'].apply(lambda x : digit_count(x))/df['message_length']

capital = r'[A-Z]+'
def capital_group(message):
  list_capital_groups = re.findall(capital,message)
  return len(list_capital_groups)

df['caps_group_count'] = df['message'].apply(lambda x:capital_group(x))

urgent_words = ['free','cash','urgent','account','winner','prize','transfer','reply','verify','now','claim','call','won','discount','deal','investment','congrats','congratulations','jackpot','chosen','service','customer','support','bank','loan','credit','bonus','voucher','gift','profit','refund','limited','click','visit','apply','login','register','update']
def urgent_word_count(message):
  pattern = r'\b(' + '|'.join(urgent_words) + r')\b'
  list_pattern = re.findall(pattern,message,flags=re.IGNORECASE)
  return len(list_pattern)

df['urgent_word_count'] = df['message'].apply(lambda x:urgent_word_count(x))

df.head()

df.columns

"""EXPLORATORY DATA ANALYSIS"""

X = df.drop(columns=['diagnosis'])

X

y = df['diagnosis']

y

"""MODEL BUILDING"""

from sklearn.compose import ColumnTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

text = 'message'
numeric = ['message_length','symbol_density','currency_count','digit_density','caps_group_count','urgent_word_count']
preprocessor = ColumnTransformer([
    ('text',TfidfVectorizer(stop_words='english'),text),
    ('num',StandardScaler(),numeric)
])

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

from sklearn.svm import SVC

full_pipeline = Pipeline([
    ('preprocessor',preprocessor),
    ('linear_svm',SVC(kernel='linear',C=1))
])

full_pipeline.fit(X_train,y_train)

"""EVALUATION"""

full_pipeline.score(X_train,y_train)*100

from sklearn.model_selection import cross_val_score

scores = cross_val_score(full_pipeline, X_train, y_train, cv=5)
print(f"Mean CV Accuracy: {scores.mean():.2%}")

from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay
y_pred = full_pipeline.predict(X_test)
print(classification_report(y_test,y_pred))

cm = confusion_matrix(y_test,y_pred)
ConfusionMatrixDisplay(cm,display_labels=full_pipeline.classes_).plot()